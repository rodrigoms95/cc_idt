{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálcula el porcentaje de error entre dos series de máximos anuales.\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import statsmodels.api        as sm\n",
    "import statsmodels.stats.api  as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTENSIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>78375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.819153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.781772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.555836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.582871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.545643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.130344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>238.204564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         INTENSIDAD\n",
       "count  78375.000000\n",
       "mean       9.819153\n",
       "std        8.781772\n",
       "min        0.555836\n",
       "25%        4.582871\n",
       "50%        7.545643\n",
       "75%       12.130344\n",
       "max      238.204564"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de celdas a eliminar del borde.\n",
    "k = 1\n",
    "\n",
    "# Archivos a evaluar.\n",
    "eval = [ [0, 2], [0, 7], [4, 5], [5, 6], [8, 6], [9, 10], [11, 12], [13, 14],\n",
    "    [15, 16], [13, 17], [14, 18], [17, 19], [14, 19], [13, 18], [13, 20],\n",
    "    [20, 14] ]\n",
    "n = 15\n",
    "i = eval[n][0]\n",
    "j = eval[n][1]\n",
    "var = \"wenzel\"\n",
    "#var = \"medido\"\n",
    "\n",
    "name = [ \"CHIRPS_interp_WRF\", \"CHIRPS_megalopolis\", \"prec_era5_hist_hist_days\",\n",
    "    \"prec_hist_comp_estaciones\", \"prec_era5_hist_hist\",\n",
    "    \"prec_mroc_hist_hist\", \"prec_mroc_2040_2040\",\n",
    "    \"prec_mroc_hist_hist_days\", \"prec_mroc_h20a_hist\",\n",
    "    \"prec_mroc_h20a_hist_coarsen_5\", \"prec_mroc_2040_2040_coarsen_5\",\n",
    "    \"WRF_regrid_CHIRPS_days_qmap\", \"WRF_2040_regrid_CHIRPS_days_qmap\",\n",
    "    \"WRF_regrid_ERA5_1985_2014_qmap\", \"WRF_regrid_ERA5_2040_2059_qmap\",\n",
    "    \"WRF_regrid_ERA5_1985_2014\", \"WRF_regrid_ERA5_2040_2059\",\n",
    "    \"WRF_regrid_ERA5_2080_2089_qmap\",\n",
    "    \"WRF_regrid_ERA5_2040_2060_100PorcUrbano_qmap\",\n",
    "    \"WRF_regrid_ERA5_2080_2089_100PorcUrbano_qmap\",\n",
    "    \"WRF_regrid_ERA5_2040_2060_sinCUS_qmap\"]\n",
    "\n",
    "fname = f\"{name[i]}_{name[j]}\"\n",
    "temp_d = \"../../../temp/cc_idt/\"\n",
    "dir = f\"{temp_d}comp/{fname}/\"\n",
    "\n",
    "# Si no existe la carpeta, la crea.\n",
    "if not os.path.exists(f\"{temp_d}comp/\"): os.mkdir(f\"{temp_d}comp/\")\n",
    "if not os.path.exists(dir): os.mkdir(dir)\n",
    "\n",
    "if var == \"wenzel\":\n",
    "    path_orig   = f\"{temp_d}SAM/{name[i]}/{name[i]}_idf_valores.nc\" \n",
    "    path_comp   = f\"{temp_d}SAM/{name[j]}/{name[j]}_idf_valores.nc\" \n",
    "if var == \"medido\":\n",
    "    path_orig   = f\"{temp_d}SAM/{name[i]}/{name[i]}_tretorno.nc\" \n",
    "    path_comp   = f\"{temp_d}SAM/{name[j]}/{name[j]}_tretorno.nc\" \n",
    "path_orig_s = f\"{temp_d}SAM/{name[i]}/{name[i]}_stats.nc\" \n",
    "path_comp_s = f\"{temp_d}SAM/{name[j]}/{name[j]}_stats.nc\" \n",
    "\n",
    "ds_orig   = xr.open_dataset(path_orig  )\n",
    "ds_comp   = xr.open_dataset(path_comp  )\n",
    "orig_stat = xr.open_dataset(path_orig_s)\n",
    "comp_stat = xr.open_dataset(path_comp_s)\n",
    "\n",
    "if k != 0:\n",
    "    ds_orig   =   ds_orig.isel(\n",
    "        {\"LONGITUD\": slice(k, -k), \"LATITUD\": slice(k, -k)} )\n",
    "    ds_comp   =   ds_comp.isel(\n",
    "        {\"LONGITUD\": slice(k, -k), \"LATITUD\": slice(k, -k)} )    \n",
    "    orig_stat = orig_stat.isel(\n",
    "        {\"LONGITUD\": slice(k, -k), \"LATITUD\": slice(k, -k)} )\n",
    "    comp_stat = comp_stat.isel(\n",
    "        {\"LONGITUD\": slice(k, -k), \"LATITUD\": slice(k, -k)} ) \n",
    "\n",
    "vars = [\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]\n",
    "\n",
    "#ds_comp[\"INTENSIDAD\"].values = ds_comp[\"INTENSIDAD\"].values[:, ::-1, :, :]\n",
    "\n",
    "# Estadísticas de los valores originales.\n",
    "ds_orig.to_dataframe()[[\"INTENSIDAD\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores entre WRF_regrid_ERA5_2040_2060_sinCUS_qmap y WRF_regrid_ERA5_2040_2059_qmap\n",
      "count: 78375.00\n",
      "mean: 0.03\n",
      "std: 0.23\n",
      "min: -0.68\n",
      "25%: -0.11\n",
      "50%: -0.00\n",
      "75%: 0.12\n",
      "max: 3.06\n"
     ]
    }
   ],
   "source": [
    "# Error total.\n",
    "if var == \"medido\":\n",
    "    ds_comp = ds_comp.drop_vars( [\"AÑO\", \"PROBABILIDAD\"] )\n",
    "    ds_orig = ds_orig.drop_vars( [\"AÑO\", \"PROBABILIDAD\"] )\n",
    "error = ( ( ds_comp - ds_orig )\n",
    "    / ds_orig ).rename( {\"INTENSIDAD\": \"P_ERROR\"} )\n",
    "#error = ( ( ds_comp.drop( [\"AÑO\", \"PROBABILIDAD\"] )\n",
    "#    - ds_orig.drop( [\"AÑO\", \"PROBABILIDAD\"] ) )\n",
    "#    / ds_orig ).rename( {\"INTENSIDAD\": \"P_ERROR\"} )\n",
    "error.to_netcdf(dir + fname + \".nc\")\n",
    "df_e = error.to_dataframe()\n",
    "\n",
    "tot = [ error[\"P_ERROR\"].count(       ).values + 0,\n",
    "        error[\"P_ERROR\"].mean(        ).values + 0,\n",
    "        error[\"P_ERROR\"].std(         ).values + 0,\n",
    "        error[\"P_ERROR\"].min(         ).values + 0,\n",
    "        error[\"P_ERROR\"].quantile(0.25).values + 0,\n",
    "        error[\"P_ERROR\"].quantile(0.5 ).values + 0,\n",
    "        error[\"P_ERROR\"].quantile(0.75).values + 0,\n",
    "        error[\"P_ERROR\"].max(         ).values + 0 ]\n",
    "\n",
    "print(f\"Errores entre {name[i]} y {name[j]}\")\n",
    "for l in range( len(vars) ): print(f\"{vars[l]}: {tot[l]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
