{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa el error de diferentes metodologías de cálculo de las curvas IDF.\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import optimize\n",
    "\n",
    "warnings.filterwarnings( \"ignore\", category = RuntimeWarning )\n",
    "\n",
    "# W: número de longitud.\n",
    "# N: número de latitud.\n",
    "W = 1\n",
    "N = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k           1.18185\n",
       "m          0.864496\n",
       "n           0.79486\n",
       "error    229.676201\n",
       "Name: (18.146495819091797, -100.39393615722656), dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Método de Wenzel sin parámetro c con regresión lineal múltiple.\n",
    "\n",
    "# Cargamos el archivo.\n",
    "i = 3\n",
    "name = [ \"CHIRPS_comp\", \"CHIRPS_megalopolis\", \"prec_hist_comp_CHIRPS\",\n",
    "    \"prec_hist_comp_estaciones\", \"prec_hist_hist\" ]\n",
    "path_ret = \"../results/\" + name[i] + \"/\" + name[i] + \"_tretorno.nc\" \n",
    "ds_ret = xr.open_dataset(path_ret)\n",
    "df = ds_ret.to_dataframe()\n",
    "\n",
    "# Quitamos la intensidad, año, probabilidad, tiempo de retorno, y agregamos\n",
    "# columnas para los parámetros de la distribución.\n",
    "df = df.reorder_levels( [\"LATITUD\",\n",
    "    \"LONGITUD\", \"DURACION\", \"TIEMPO_RETORNO\"] )\n",
    "df_2 = df.copy().drop( [\"PROBABILIDAD\", \"AÑO\"], axis = 1 \n",
    "    ).reset_index( \"TIEMPO_RETORNO\" )\n",
    "df_2 = df_2.reset_index( \"DURACION\" )\n",
    "df_3 = df_2.copy().drop(\n",
    "    [\"INTENSIDAD\", \"TIEMPO_RETORNO\", \"DURACION\"], axis = 1\n",
    "    ).groupby( [\"LATITUD\", \"LONGITUD\"] ).mean()\n",
    "cols = [\"k\", \"m\", \"n\", \"error\"]\n",
    "df_3[ cols ] = None\n",
    "\n",
    "# Escogemos latitud y longitud.\n",
    "i = df_3.index.get_level_values(\"LATITUD\").unique()[N]\n",
    "j = df_3.index.get_level_values(\"LONGITUD\").unique()[W]\n",
    "\n",
    "# Creamos la tabla a predecir.\n",
    "t = ( ( [5, 10, 25, 50, 100, 200, 500, 1000] + [None] *\n",
    "    ( df_2[\"TIEMPO_RETORNO\"].unique().shape[0] - 8 ) )\n",
    "    * df_2.index.get_level_values(\"LONGITUD\").unique().shape[0]\n",
    "    * df_2.index.get_level_values(\"LATITUD\").unique().shape[0]\n",
    "    * df_2[\"DURACION\"].unique().shape[0] )\n",
    "df_2[\"TIEMPO_RETORNO\"] = t\n",
    "df_2 = df_2.dropna().set_index( \"TIEMPO_RETORNO\", append = True )\n",
    "\n",
    "# Función que nos genera una curva idT.\n",
    "def idT(X, k, m, n):\n",
    "    return ( k * X[0] ** m ) / X[1] ** n\n",
    "\n",
    "# Regresión lineal múltiple.\n",
    "df_4 = np.log( df.loc[ (i, j), \"INTENSIDAD\" ].reset_index() )\n",
    "df_4[\"1\"] = 1\n",
    "# Predictando.\n",
    "Y = df_4[\"INTENSIDAD\"]\n",
    "# Predictores.\n",
    "X = df_4[ [\"1\", \"TIEMPO_RETORNO\", \"DURACION\"] ]\n",
    "# Coeficientes de regresión.\n",
    "B = np.linalg.inv( X.T @ X ) @ ( X.T @ Y )\n",
    "\n",
    "# Coeficientes de las curvas idT.\n",
    "df_3.loc[ (i, j), cols[0] ] = np.exp(B[0])\n",
    "df_3.loc[ (i, j), cols[1] ] = B[1]\n",
    "df_3.loc[ (i, j), cols[2] ] = -B[2]\n",
    "# Error\n",
    "X = np.swapaxes( df.loc[ (i, j) ].reset_index(\n",
    "    )[ [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "df_3.loc[ (i, j), cols[3] ] = ( ( df.loc[ (i, j)\n",
    "    ].reset_index()[\"INTENSIDAD\"].values - idT( \n",
    "    X, *df_3.loc[ (i, j) ].iloc[0:3] ) ) ** 2 ).sum()\n",
    "\n",
    "# Calculamos las intensidades.\n",
    "X = np.swapaxes( df_2.loc[ (i, j) ].reset_index()[\n",
    "    [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "df_2.loc[ (i, j), \"INTENSIDAD\"] = idT(X, *df_3.loc[ (i, j) ].iloc[0:3] )\n",
    "\n",
    "# Coeficientes\n",
    "df_3.loc[ (i, j) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k          0.953427\n",
       "m          1.011362\n",
       "n          0.913854\n",
       "error    137.758543\n",
       "Name: (18.146495819091797, -100.39393615722656), dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Método de Wenzel sin parámetro c con mínimos cuadrados no lineales.\n",
    "\n",
    "# Cargamos el archivo.\n",
    "i = 3\n",
    "name = [ \"CHIRPS_comp\", \"CHIRPS_megalopolis\", \"prec_hist_comp_CHIRPS\",\n",
    "    \"prec_hist_comp_estaciones\", \"prec_hist_hist\" ]\n",
    "path_ret = \"../results/\" + name[i] + \"/\" + name[i] + \"_tretorno.nc\"\n",
    "ds_ret = xr.open_dataset(path_ret)\n",
    "df = ds_ret.to_dataframe()\n",
    "\n",
    "# Quitamos la intensidad, año, probabilidad, tiempo de retorno, y agregamos\n",
    "# columnas para los parámetros de la distribución.\n",
    "df = df.reorder_levels( [\"LATITUD\",\n",
    "    \"LONGITUD\", \"DURACION\", \"TIEMPO_RETORNO\"] )\n",
    "df_2 = df.copy().drop( [\"PROBABILIDAD\", \"AÑO\"], axis = 1 \n",
    "    ).reset_index( \"TIEMPO_RETORNO\" )\n",
    "df_2 = df_2.reset_index( \"DURACION\" )\n",
    "df_3 = df_2.copy().drop(\n",
    "    [\"INTENSIDAD\", \"TIEMPO_RETORNO\", \"DURACION\"], axis = 1\n",
    "    ).groupby( [\"LATITUD\", \"LONGITUD\"] ).mean()\n",
    "cols = [\"k\", \"m\", \"n\", \"error\"]\n",
    "df_3[ cols ] = None\n",
    "\n",
    "# Creamos la tabla a predecir.\n",
    "t = ( ( [5, 10, 25, 50, 100, 200, 500, 1000] + [None] *\n",
    "    ( df_2[\"TIEMPO_RETORNO\"].unique().shape[0] - 8 ) )\n",
    "    * df_2.index.get_level_values(\"LONGITUD\").unique().shape[0]\n",
    "    * df_2.index.get_level_values(\"LATITUD\").unique().shape[0]\n",
    "    * df_2[\"DURACION\"].unique().shape[0] )\n",
    "df_2[\"TIEMPO_RETORNO\"] = t\n",
    "df_2 = df_2.dropna().set_index( \"TIEMPO_RETORNO\", append = True )\n",
    "\n",
    "# Escogemos latitud y longitud.\n",
    "i = df_3.index.get_level_values(\"LATITUD\").unique()[N]\n",
    "j = df_3.index.get_level_values(\"LONGITUD\").unique()[W]\n",
    "\n",
    "# Función que nos genera una curva idT.\n",
    "def idT(X, k, m, n):\n",
    "    return ( k * X[0] ** m ) / X[1] ** n\n",
    "\n",
    "# Mínimos cuadrados no lineales.\n",
    "df_4 = df.loc[ (i, j), \"INTENSIDAD\" ].reset_index()\n",
    "# Predictando.\n",
    "Y = df_4[\"INTENSIDAD\"].values\n",
    "# Predictores.\n",
    "X = np.swapaxes( df_4[ [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "# Cálculo de parámetros.\n",
    "fit = optimize.curve_fit( f = idT, xdata = X, ydata = Y,\n",
    "    p0 = (1, 1, 1), full_output = True )\n",
    "\n",
    "# Coeficientes de las curvas idT.\n",
    "df_3.loc[ (i, j), cols[:-1] ] = fit[0]\n",
    "# Error.\n",
    "df_3.loc[ (i, j), cols[-1] ] = ( fit[2][\"fvec\"] ** 2 ).sum()\n",
    "\n",
    "# Calculamos las intensidades.\n",
    "X = np.swapaxes( df_2.loc[ (i, j) ].reset_index()[\n",
    "    [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "df_2.loc[ (i, j), \"INTENSIDAD\"] = idT(X, *df_3.loc[ (i, j) ].iloc[0:3] )\n",
    "\n",
    "# Coeficientes\n",
    "df_3.loc[ (i, j) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k          0.989165\n",
       "m          1.011334\n",
       "n          0.931184\n",
       "c          0.042076\n",
       "error    137.715232\n",
       "Name: (18.146495819091797, -100.39393615722656), dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Método de Wenzel con mínimos cuadrados no lineales.\n",
    "\n",
    "# Cargamos el archivo.\n",
    "i = 3\n",
    "name = [ \"CHIRPS_comp\", \"CHIRPS_megalopolis\", \"prec_hist_comp_CHIRPS\",\n",
    "    \"prec_hist_comp_estaciones\", \"prec_hist_hist\" ]\n",
    "path_ret = \"../results/\" + name[i] + \"/\" + name[i] + \"_tretorno.nc\"\n",
    "ds_ret = xr.open_dataset(path_ret)\n",
    "df = ds_ret.to_dataframe()\n",
    "\n",
    "# Quitamos la intensidad, año, probabilidad, tiempo de retorno, y agregamos\n",
    "# columnas para los parámetros de la distribución.\n",
    "df = df.reorder_levels( [\"LATITUD\",\n",
    "    \"LONGITUD\", \"DURACION\", \"TIEMPO_RETORNO\"] )\n",
    "df_2 = df.copy().drop( [\"PROBABILIDAD\", \"AÑO\"], axis = 1 \n",
    "    ).reset_index( \"TIEMPO_RETORNO\" )\n",
    "df_2 = df_2.reset_index( \"DURACION\" )\n",
    "df_3 = df_2.copy().drop(\n",
    "    [\"INTENSIDAD\", \"TIEMPO_RETORNO\", \"DURACION\"], axis = 1\n",
    "    ).groupby( [\"LATITUD\", \"LONGITUD\"] ).mean()\n",
    "cols = [\"k\", \"m\", \"n\", \"c\", \"error\"]\n",
    "df_3[ cols ] = None\n",
    "\n",
    "# Creamos la tabla a predecir.\n",
    "t = ( ( [5, 10, 25, 50, 100, 200, 500, 1000] + [None] *\n",
    "    ( df_2[\"TIEMPO_RETORNO\"].unique().shape[0] - 8 ) )\n",
    "    * df_2.index.get_level_values(\"LONGITUD\").unique().shape[0]\n",
    "    * df_2.index.get_level_values(\"LATITUD\").unique().shape[0]\n",
    "    * df_2[\"DURACION\"].unique().shape[0] )\n",
    "df_2[\"TIEMPO_RETORNO\"] = t\n",
    "df_2 = df_2.dropna().set_index( \"TIEMPO_RETORNO\", append = True )\n",
    "\n",
    "# Escogemos latitud y longitud.\n",
    "i = df_3.index.get_level_values(\"LATITUD\").unique()[N]\n",
    "j = df_3.index.get_level_values(\"LONGITUD\").unique()[W]\n",
    "\n",
    "# Función que nos genera una curva idT.\n",
    "def idT(X, k, m, n, d):\n",
    "    return ( k * X[0] ** m ) / ( X[1] + d ) ** n\n",
    "\n",
    "# Mínimos cuadrados no lineales.\n",
    "df_4 = df.loc[ (i, j), \"INTENSIDAD\" ].reset_index()\n",
    "# Predictando.\n",
    "Y = df_4[\"INTENSIDAD\"].values\n",
    "# Predictores.\n",
    "X = np.swapaxes( df_4[ [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "# Cálculo de parámetros.\n",
    "fit = optimize.curve_fit( f = idT, xdata = X, ydata = Y,\n",
    "    p0 = (1, 1, 1, 1), full_output = True )\n",
    "\n",
    "# Coeficientes de las curvas idT.\n",
    "df_3.loc[ (i, j), cols[:-1] ] = fit[0]\n",
    "# Error.\n",
    "df_3.loc[ (i, j), cols[-1] ] = ( fit[2][\"fvec\"] ** 2 ).sum()\n",
    "\n",
    "# Calculamos las intensidades.\n",
    "X = np.swapaxes( df_2.loc[ (i, j) ].reset_index()[\n",
    "    [\"TIEMPO_RETORNO\", \"DURACION\"] ].values, 0, 1 )\n",
    "df_2.loc[ (i, j), \"INTENSIDAD\"] = idT(X, *df_3.loc[ (i, j) ].iloc[0:4] )\n",
    "\n",
    "# Coeficientes\n",
    "df_3.loc[ (i, j) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 638.001038\n"
     ]
    }
   ],
   "source": [
    "# Distribución de Valores Extremos Generalizada.\n",
    "\n",
    "# Cargamos el archivo.\n",
    "i = 3\n",
    "name = [ \"CHIRPS_comp\", \"CHIRPS_megalopolis\", \"prec_hist_comp_CHIRPS\",\n",
    "    \"prec_hist_comp_estaciones\", \"prec_hist_hist\" ]\n",
    "path_ret = \"../results/\" + name[i] + \"/\" + name[i] + \"_tretorno.nc\"\n",
    "ds_ret = xr.open_dataset(path_ret)\n",
    "df = ds_ret.to_dataframe()\n",
    "\n",
    "# Quitamos la intensidad, año, probabilidad, tiempo de retorno, y agregamos\n",
    "# columnas para los parámetros de la distribución.\n",
    "df = df.reorder_levels( [\"LATITUD\",\n",
    "    \"LONGITUD\", \"DURACION\", \"TIEMPO_RETORNO\"] )\n",
    "df_2 = df.copy().drop( [\"PROBABILIDAD\", \"AÑO\"], axis = 1 \n",
    "    ).reset_index( \"TIEMPO_RETORNO\" )\n",
    "#df_2 = df_2.reset_index( \"DURACION\" )\n",
    "df_3 = df_2.copy().drop( [\"INTENSIDAD\", \"TIEMPO_RETORNO\"], axis = 1\n",
    "    ).groupby( [\"LATITUD\", \"LONGITUD\", \"DURACION\"] ).mean()\n",
    "cols = [\"GEV_C\", \"GEV_LOC\", \"GEV_SCALE\", \"KTEST_P\"]\n",
    "df_3[ cols ] = None\n",
    "\n",
    "# Creamos la tabla a predecir.\n",
    "t = ( ( [5, 10, 25, 50, 100, 200, 500, 1000] + [None] *\n",
    "    ( df_2[\"TIEMPO_RETORNO\"].unique().shape[0] - 8 ) )\n",
    "    * df_2.index.get_level_values(\"LONGITUD\").unique().shape[0]\n",
    "    * df_2.index.get_level_values(\"LATITUD\").unique().shape[0]\n",
    "    * df_2.index.get_level_values(\"DURACION\").unique().shape[0] )\n",
    "df_2[\"TIEMPO_RETORNO\"] = t\n",
    "df_2 = df_2.dropna().set_index( \"TIEMPO_RETORNO\", append = True )\n",
    "\n",
    "# Escogemos latitud y longitud.\n",
    "i = df_3.index.get_level_values(\"LATITUD\").unique()[N]\n",
    "j = df_3.index.get_level_values(\"LONGITUD\").unique()[W]\n",
    "\n",
    "df_4 = df.loc[ (i, j), [\"INTENSIDAD\"] ]\n",
    "\n",
    "# Ajuste de la distribución GEV por duración.\n",
    "for k in df_3.index.get_level_values(\"DURACION\").unique():\n",
    "    # ajustamos la distribución de valores extremos.\n",
    "    params = stats.genextreme.fit( df.loc[ (i, j, k), \"INTENSIDAD\" ] )\n",
    "    # Hacemos la prueba Kolmogorov Smirnoff.\n",
    "    pvalue = stats.kstest( df.loc[ (i, j, k), \"INTENSIDAD\" ],\n",
    "    stats.genextreme(*params).cdf ).pvalue\n",
    "    df_3.loc[ (i, j, k), cols ] = [*params] + [pvalue]\n",
    "    # Calculamos las intensidades de acuerdo con la distribución.\n",
    "    df_2.loc[ (i, j, k), \"INTENSIDAD\"] = stats.genextreme(\n",
    "        *df_3.loc[ (i, j, k), cols[:-1] ] ).isf(\n",
    "        1 / df_2.loc[ (i, j, k) ].index.get_level_values(\"TIEMPO_RETORNO\") )\n",
    "    # Calculamos las intensidades para calcular el error.\n",
    "    df_4.loc[ (k), \"INTENSIDAD\" ] = stats.genextreme(\n",
    "        *df_3.loc[ (i, j, k), cols[:-1] ] ).isf(\n",
    "        1 / df_4.loc[ (k) ].index.get_level_values(\"TIEMPO_RETORNO\") )\n",
    "    \n",
    "# Error.\n",
    "error = ( ( df_4[\"INTENSIDAD\"] - df.loc[ (i, j), \"INTENSIDAD\" ] ) ** 2 ).sum()\n",
    "print(f\"Error: {error:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
